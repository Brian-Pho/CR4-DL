{"componentChunkName":"component---src-templates-post-template-tsx","path":"/books/a-thousand-brains/","result":{"data":{"markdownRemark":{"html":"<h1 id=\"part-i-a-new-understanding-of-the-brain\" style=\"position:relative;\"><a href=\"#part-i-a-new-understanding-of-the-brain\" aria-label=\"part i a new understanding of the brain permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Part I: A New Understanding of the Brain</h1>\n<ul>\n<li>A nerve impulse from the eye is no different than one from the ear or the big toe.</li>\n<li>It’s where they end up in the brain that sorts them out.</li>\n<li>The cells in your head are reading these words, which is remarkable because cells are simple— they can’t read, think, or do much of anything.</li>\n<li>Yet enough cells together make a brain that can not only read, but can also decipher the mysteries of the universe.</li>\n<li>How does a brain made of simple cells create intelligence?</li>\n<li>Understanding how the brain works is considered one of humanity’s grand challenges alongside understanding the nature of the universe.</li>\n<li>We have learned a tremendous amount of knowledge and facts about the brain, but we understand little of how the whole thing works; we lack a theory to interpret these results.</li>\n<li>The author and his team have been working for the past 15 years on understanding the neocortex.</li>\n<li>An intelligent brain needs to learn a lot.</li>\n<li>E.g. What everyday objects look, feel, and sound like. How to open and close different types of doors.</li>\n<li>Every person possesses a tremendous amount of knowledge about the world.</li>\n<li>Model: an organization of facts that reflects the structure of the world.</li>\n<li>E.g. To know what a bicycle is, we don’t just remember a list of bicycle facts, but instead our brain organizes the facts into different parts, how the parts are arranged, and how the parts function to form a model of a bicycle.</li>\n<li>Intelligence is intimately tied to the brain’s model of the world.</li>\n<li>The author argues that the neocortex stores everything we know using reference frames.</li>\n<li>The brain’s model of the world is built using hundreds of thousands of map-like reference frames.</li>\n<li>Most of the cells in your neocortex are dedicated to creating and manipulating reference frames.</li>\n<li>No notes on the author’s career into neuroscience and the creation of Numenta.</li>\n<li>Numenta is a company whose goal is to develop a theory of how the neocortex works.</li>\n</ul>\n<h2 id=\"chapter-1-old-brainnew-brain\" style=\"position:relative;\"><a href=\"#chapter-1-old-brainnew-brain\" aria-label=\"chapter 1 old brainnew brain permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 1: Old Brain—New Brain</h2>\n<ul>\n<li>The brain evolved by adding new parts on top of older parts.</li>\n<li>The old brain parts are still there because regardless of how smart and sophisticated we become, we still need to breath, eat, and reproduce to survive.</li>\n<li>This idea of an old and new brain is not supported by current science (see <a href=\"https://brianpho.com/CR4-DL/papers/neuroscience-set-4/#your-brain-is-not-an-onion-with-a-tiny-reptile-inside\">this</a>).</li>\n<li>The neocortex occupies about 70 percent by volume of the brain and is the organ of intelligence.</li>\n<li>If we want to understand intelligence, then we have to understand what the neocortex does and how it does it.</li>\n<li>The neocortex doesn’t control behavior directly as none of its neurons directly connect to muscles.</li>\n<li>Instead, it tells the old brain what behavior it wants and lets the old brain execute it.</li>\n<li>The neocortex is divided into different areas with different functions.</li>\n<li>When it’s damaged, deficits arise depending on what part of the neocortex was affected.</li>\n<li>There is both evidence for and against the idea that the neocortex is organized as a hierarchy.</li>\n<li>E.g. Increases in feature complexity from edges to shapes to objects, but the divisions between levels and regions aren’t clear.</li>\n<li>The neurons in the neocortex appear to be organized into six layers that run parallel to the surface of the neocortex.</li>\n<li>The layers appear due to differences in the size and density of neurons.</li>\n<li>Layer 1 is the outermost surface of the neocortex closest to the skull, while Layer 6 is the closest to the center of the brain.</li>\n<li>Another observation of the neocortex is that most of the connections between neurons are vertical and between layers.</li>\n<li>Three general observations about the neocortex\n<ol>\n<li>Local circuits in the neocortex are complex.\n<ul>\n<li>In a 1 mm x 1 mm x 2.5 mm volume of neocortex, there are about 100,000 neurons, 500 million synapses, and several kilometers of axons and dendrites.</li>\n<li>The precise and extremely complex neural circuits seen in the neocortex tell us that every region is doing something far more complex than just feature detection.</li>\n</ul>\n</li>\n<li>Neocortex looks similar everywhere.\n<ul>\n<li>At a high level, the circuitry of the neocortex looks similar in visual regions, language regions, and touch regions.</li>\n<li>It even looks similar across different species such as between humans, rodents, and cats.</li>\n<li>But there are differences, and we believe these differences lead to some functional benefit.</li>\n<li>Overall, the variations between regions are relatively small compared to the similarities.</li>\n</ul>\n</li>\n<li>Every part of the neocortex generates movement.\n<ul>\n<li>It’s incorrect to believe that information went to the sensory regions, was processed, and then went down to the motor regions to enact behavior.</li>\n<li>We now know that neurons in every region project to a region related to movement.</li>\n<li>E.g. The visual regions send out signals to regions responsible for moving the eyes. The auditory regions send out signals to regions responsible for moving the head.</li>\n<li>Evidence suggests that the complex circuitry seen everywhere in the neocortex performs a sensory-motor task. Thus, there are no pure motor nor sensory regions.</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"chapter-2-vernon-mountcastles-big-idea\" style=\"position:relative;\"><a href=\"#chapter-2-vernon-mountcastles-big-idea\" aria-label=\"chapter 2 vernon mountcastles big idea permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 2: Vernon Mountcastle’s Big Idea</h2>\n<ul>\n<li>Vernon Mountcastle wrote an important monograph in 1978 about the brain.</li>\n<li>Mountcastle argued that the neocortex got big not by creating anything new, but by repeatedly copying a basic neural circuit.</li>\n<li>The human neocortex is much larger than a rat or dog neocortex but they’re all made from the same element; just that the human neocortex has more copies of that element.</li>\n<li>Mountcastle proposed that the reason brain regions look similar is because they’re performing similar functions.</li>\n<li>What makes regions different isn’t their intrinsic function but what they’re connected to.</li>\n<li>E.g. If you connect eyes, you get vision. If you connect ears, you get audition. If you connect other brain regions, you get higher-order thought like language.</li>\n<li>Thus, by understanding the fundamental function of any part of the neocortex, we will understand the entire neocortex.</li>\n<li>The fundamental unit of the neocortex, the unit of intelligence, is called a “cortical column”.</li>\n<li>A cortical column is like a piece of spaghetti and about 150,000 of them are stacked vertically beside each other.</li>\n<li>Evidence for the cortical column comes from experiments where all cells in one column of neocortex respond to the same spot of retina or the same patch of skin, but then cells in the next column all respond to a different part of the retina or skin.</li>\n<li>The grouping of responses is what defines a column and is seen everywhere in the neocortex.</li>\n<li>A cortical column can be further subdivided into minicolumns.</li>\n<li>What function do cortical columns or minicolumns perform? Mountcastle didn’t know and didn’t guess.</li>\n<li>Being able to learn practically anything requires the brain to work on a universal principle. (Is this true?)</li>\n<li>If we can figure out what a cortical column does, then we’ve figured out how the neocortex works and, by extension, how the brain works.</li>\n</ul>\n<h2 id=\"chapter-3-a-model-of-the-world-in-your-head\" style=\"position:relative;\"><a href=\"#chapter-3-a-model-of-the-world-in-your-head\" aria-label=\"chapter 3 a model of the world in your head permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 3: A Model of the World in Your Head</h2>\n<ul>\n<li>Unlike a reflex, the input to the neocortex might be acted on in an hour, in a year, or maybe never.</li>\n<li>Since the neocortex doesn’t and can’t know if the information will be useful, it stores it.</li>\n<li>In a familiar environment, you notice any small changes.</li>\n<li>E.g. If the cup on your office desk is on the wrong side, if the stapler makes the wrong sound. These small changes are noticed by you.</li>\n<li>How does the brain know something changed?</li>\n<li>It knows because it’s making multiple simultaneous predictions of what it’s about to see, hear, and feel.</li>\n<li>E.g. When you’re about to pick something up, your brain predicts the object’s weight, size, texture, density, etc.</li>\n<li>Thus, every action leads to a prediction of what should be received by the brain.</li>\n<li>Prediction is a universal function of the neocortex.</li>\n<li>To make predictions, the brain has to learn what’s normal or what’s expected based on past experience.</li>\n<li>In other words, the neocortex learns a model of the world and makes it predictions based on this model.</li>\n<li>Prediction is constantly happening in the brain and it isn’t something the brain does sporadically; it’s an intrinsic property.</li>\n<li>When a prediction is correct, we won’t be aware that it ever occurred.</li>\n<li>When we are born, our neocortex doesn’t know anything and has no model for how to speak, how doors work, how to drive, etc. Instead, it has to learn.</li>\n<li>The general structure of the neocortex isn’t random as our genes determine which regions connect with which sensory organ at birth.</li>\n<li>But it’s also true that the neocortex doesn’t know what it will see, hear, or what languages it might learn.</li>\n<li>So the neocortex starts with some built-in assumptions but nothing specific.</li>\n<li>Through experience, it learns a rich and complicated model of the world.</li>\n<li>For every item you come across, you can recall experiences associated with it and how you interacted with it.</li>\n<li>The number of things you know is enormous and your library of knowledge seems endless.</li>\n<li>Two ways the input to the brain can change\n<ul>\n<li>The world can change.\n<ul>\n<li>E.g. The sun rises and falls causing objects to become brighter and darker.</li>\n</ul>\n</li>\n<li>We can change.\n<ul>\n<li>E.g. We move when walking, which changes what we see, feel, and hear.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>The only way the brain learns its model of the world is by observing how its inputs change over time.</li>\n<li>The brain learns sensory-motor learning loops by perceiving how our sensory inputs change as we move.</li>\n<li>With each movement, the neocortex predicts what the next sensation will be.</li>\n<li>How does the neocortex, which is composed of thousands of similar cortical columns, learn a predictive model of the world through movement?</li>\n<li>If we can answer this, then maybe we could build machines that worked the same way.</li>\n<li>Review of neurons, axons, dendrites, action potentials, and synapses.</li>\n<li>Two tenets of neuroscience\n<ol>\n<li>Thoughts, ideas, and perceptions are the activity of neurons.\n<ul>\n<li>A small fraction of neurons in the brain are actively spiking at any point in time.</li>\n<li>This activity determines your thoughts, ideas, and perceptions.</li>\n<li>Stimulating the neocortex using a tiny probe results in experiences dependent upon which neurons were activated.</li>\n<li>Neurons can participate in many different thoughts and experiences.</li>\n<li>Our mental states and the activity of neurons are one and the same.</li>\n</ul>\n</li>\n<li>Everything we know is stored in the connections between neurons.\n<ul>\n<li>The brain remembers a lot and this knowledge is stored using synapses.</li>\n<li>Review of Hebbian learning.</li>\n<li>Learning involves increasing or decreasing the strength of synapses, creating and deleting synapses, and creating and deleting neurons.</li>\n<li>The connections in our brain store a model of the world learned through our experiences.</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"chapter-4-the-brain-reveals-its-secrets\" style=\"position:relative;\"><a href=\"#chapter-4-the-brain-reveals-its-secrets\" aria-label=\"chapter 4 the brain reveals its secrets permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 4: The Brain Reveals Its Secrets</h2>\n<ul>\n<li>The brain seems complicated because we don’t understand how it works.</li>\n<li>The author, however, describes some key moments when our understanding of the brain dramatically changed.</li>\n<li>Discovery 1: The neocortex learns a predictive model of the world.\n<ul>\n<li>Learning a model of the world and making predictions isn’t the only thing the neocortex does, but it’s one of its most important tasks.</li>\n<li>How does the brain make predictions?</li>\n<li>Maybe the brain has one set of neurons for handling sensations and another set of neurons for predicting those sensations. The brain must keep these two sets of neurons separate to avoid hallucinating.</li>\n<li>This idea has problems though as we haven’t observed the expected number of neurons dedicated to prediction.</li>\n<li>Another problem is how we aren’t aware of the constant predictions made by the brain unless an error occurs.</li>\n</ul>\n</li>\n<li>Discovery 2: Predictions occur inside neurons.\n<ul>\n<li>Recall the two types of predictions: when the world changes and when you move.</li>\n<li>Perhaps every cortical column in the neocortex makes both types of predictions.</li>\n<li>Suppose we focus on predicting the next item in a sequence.</li>\n<li>E.g. Next melody in a song, next word in a speech, next movement in an action.</li>\n<li>How do neurons in a cortical column learn sequences?</li>\n<li>Neurons don’t know how far back in the past they have to remember to predict the next item.</li>\n<li>E.g. To predict the next musical note, do we need the past one note, past five notes, or past hundred notes?</li>\n<li>Neurons have to figure out how much context is needed to make the right prediction; also called the sequence-memory problem.</li>\n<li>Most of the solutions we tried worked to an extent but none completely matched the biological details of the brain.</li>\n<li>We weren’t interested in a partial solution or a biologically inspired solution, we wanted to know exactly how the brain learns sequences and makes predictions.</li>\n<li>The key insight was a new way of thinking about neurons.</li>\n<li>Review of dendritic spikes: an action potential generated in a dendrite.</li>\n<li>The author argues that dendritic spikes are predictions by priming the target neuron into a predictive state. Then, if the neuron gets enough input it spikes sooner than if the neuron wasn’t in a predictive state.</li>\n<li>If one or more of the neurons in a minicolumn are in the predictive state, our theory says that only those neurons spike and the other neurons are inhibited.</li>\n<li>So, when an unexpected input arrives, multiple neurons fire. But if the expected input arrives, only the predictive-state neurons fire.</li>\n<li>This matches a common observation about the neocortex that unexpected inputs cause a lot more activity than expected ones.</li>\n<li>The sequence-memory problem can be solved by several thousand neurons in a minicolumn with a few inhibitory neurons.</li>\n<li>Prediction is built into the fabric of the neocortex.</li>\n</ul>\n</li>\n<li>Discovery 3: The secret of the cortical column is reference frames.\n<ul>\n<li>How does the neocortex predict the next input when we move?</li>\n<li>For a cortical column to predict its next input, it must know what movement will be performed.</li>\n<li>Specifically, it needs to know what object it’s touching and where the limb doing the touching will be after it moves.</li>\n<li>E.g. If you have your finger on the wall of a coffee cup and move up, you predict that you’ll feel the lip/edge of the cup.</li>\n<li>What matters isn’t where the limb is relative to the body or where the object is relative to the body, what matters is the location of the limb relative to the object.</li>\n<li>It’s puzzling if and how neurons could attach a reference frame to an object.</li>\n<li>Reference frame: like an invisible 3D grid surrounding and attached to the object.</li>\n<li>Different parts of your body can touch the object simultaneously, so each body part makes a separate prediction of what it’ll feel based on the location it touches the cup.</li>\n<li>The neocortex must know the location, relative to the object, of every part of your body touching the object.</li>\n<li>The same idea applies to vision as different patches of the retina see different parts of an object and the neocortex assigns each retinal patch to a location relative to the object.</li>\n<li>However, creating reference frames, especially object-centered ones, are difficult.</li>\n<li>The author believes that this complex calculation is performed by the various layers of the neocortex, and since the neocortex looks similar throughout the brain, each column in the neocortex must have neurons that represent reference frames and locations.</li>\n<li>Instead of mainly processing sensory inputs, the neocortex mainly processes reference frames.</li>\n<li>Reference frames are important because they allow the brain to learn the structure of objects. By learning the structure, the brain can manipulate the entire object either mentally or physically.</li>\n</ul>\n</li>\n<li>The third discovery took over three years to work out its implications.</li>\n<li>But how do neurons actually create reference frames?</li>\n<li>We might find an answer by looking to the entorhinal cortex.</li>\n<li>Chapter summary\n<ul>\n<li>The idea that every cortical column in the neocortex creates reference frames.</li>\n<li>We started with the premise that the neocortex learns a rich and detailed model of the world, which it uses to constantly predict what its next sensory inputs will be.</li>\n<li>Neurons make these predictions using dendritic spikes that make the target neuron fire sooner.</li>\n<li>This leads to neurons that can learn and predict sequences such as the next sensory input when we move.</li>\n<li>To make these sensory-motor predictions, each cortical column must know the location of its input relative to the object being sensed.</li>\n<li>This requires a cortical column to have a reference frame fixed to the object.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"chapter-5-mapsin-the-brain\" style=\"position:relative;\"><a href=\"#chapter-5-mapsin-the-brain\" aria-label=\"chapter 5 mapsin the brain permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 5: Mapsin the Brain</h2>\n<ul>\n<li>When we see, light hits the back of the retina but we don’t perceive objects as being in the eye.</li>\n<li>The same applies to audition: why don’t we perceive the sound of a car as in your ear even though that’s where the sound actually is?</li>\n<li>This observation, that we perceive stimuli as being somewhere out there in the world instead of at our sense organs, tells us that the brain must represent the location of every object we perceive.</li>\n<li>Simple organisms don’t need to know where they’re located, but knowing where you are is an advantage.</li>\n<li>E.g. You can map places of shelter, food, warmth, etc. relative to your current location.</li>\n<li>However, to know where you are requires a reference frame.</li>\n<li>Being able to navigate the world is crucial to survival and was thus prioritized by evolution.</li>\n<li>In our brains, the map-creating neurons are in the hippocampus and entorhinal cortex.</li>\n<li>Review of the discovery of place cells in the hippocampus: neurons that fire every time the rat was in a specific location in a specific environment.</li>\n<li>A place cell is like a “you are here” marker on a map.</li>\n<li>Review of the discovery of grid cells in the entorhinal cortex: neurons that fire at multiple locations in an environment in a grid-like pattern.</li>\n<li>Both place and grid cells work together to create a map of the environment and to track your position in that environment.</li>\n<li>E.g. If you close your eyes and walk a few steps forwards, you know that you’re in a different location even though the sensory information hasn’t changed.</li>\n<li>Knowing the location of your finger relative to a coffee cup is similar to knowing the location of your body relative to the room.</li>\n<li>So, maybe the neocortex has neurons similar to the place and grid cells in the hippocampus and entorhinal cortex.</li>\n<li>Grid and place cells mostly track the location of one thing: the body. In contrast, the neocortex would have to track the location of thousands of objects simultaneously.</li>\n<li>No notes on the maps-cut-into-squares example.</li>\n<li>When you touch and explore an unknown object with one finger, you might have to move your finger to learn more about the object.</li>\n<li>By moving, you discover two things: what the object is and where your finger is on the object.</li>\n<li>How are map-like models implemented by neurons in the neocortex?</li>\n<li>Our theory argues that every cortical column can learn models of complete objects.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 348px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/CR4-DL/static/5efe33eff87a50fa98b406e06ccf1b14/34ea4/figure-cortical-column-model.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 92.8%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAIAAAAf7rriAAAACXBIWXMAAAsTAAALEwEAmpwYAAACOUlEQVQ4y41TbXOiMBj0//+gzrSjZY4WagdaUUwgsRQTBIGgolAoL4GbNj3Hq3bu9lsm2X02u8mg/4Ou6/q+L4piNBrNZjPLsiCEAACEkKqqz8/PxzNHDLq/0fe9bdtVVZ0q+r5PKe37vm1bzvlRYtCfYTqd+r6/3W6TJGGM7fd7AAAh5MLkJEk2m404Wr6/Z3kuy7KmaaZpTj8xn88lSfI8z/f9yWRiGEYQBEJogBCybXu5XEII397eNpvNL1mez+eO42CMHcdZLt2HhwfP8zBeqKqqaVqe51/kUxvC1WQyeX19dV13tVoBACmlhmEQQqqqiuN4u91yzi8H1nUdhLBtW8ZY0zSuuyyKMgzDy3c+DwwAUNd1FEVlWUZR3LY8CAJBPo36R3LTNIwldV2HYcQ5X6/Xlyd/K1mQOeeUemm6Z4xx3q3Xa9Fz0zT/7jmOY9d1/U+kaYoQOtoW84XEIM/zLMvyPK+qqmmatm3H47GuPyGExAtFCMmyTAjZ7XYY45eXlyzLvqoyTdMwDMuykiRJ0zQMw9tbaTab2bZtWZZt2xjj+/t7z/MopYqiAAAsyyKEHA6HCz0/PX2MXa1WlFJCSBAEuq4TQrIsc12XMeZ84oN8HhjGuK7rU7kgCERgP/YsNsqyvLm5OdqGEC4Wi7u7O13Xxa8SaX0FdiSLdVVVjLE4ZvEJoije7XbnvVyo6v8xEG4Ph4OmaZIkXV1dKYpimqaqqsPhaDgcPj4+Xl9fK4pSFMW3a/8GlG4mZE8dba4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Figure Cortical Column Model\"\n        title=\"Figure Cortical Column Model\"\n        src=\"/CR4-DL/static/5efe33eff87a50fa98b406e06ccf1b14/34ea4/figure-cortical-column-model.png\"\n        srcset=\"/CR4-DL/static/5efe33eff87a50fa98b406e06ccf1b14/63868/figure-cortical-column-model.png 250w,\n/CR4-DL/static/5efe33eff87a50fa98b406e06ccf1b14/34ea4/figure-cortical-column-model.png 348w\"\n        sizes=\"(max-width: 348px) 100vw, 348px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></li>\n<li>The upper layer of the column receives sensory input while the lower layer represents the current location in a reference frame.</li>\n<li>The upper layer is similar to place cells and the lower layer is similar to grid cells.</li>\n<li>Learning a new object means the neocortex learns new connections between these two layers.</li>\n<li>The connections between the upper and lower layers represent the connections between a blank reference frame and what’s seen at that location.</li>\n<li>If you know the feature, you can determine the location and vice versa.</li>\n<li>E.g. A coffee cup is defined by a set of observed features (upper layer) associated with a set of locations on the cup (lower layer).</li>\n<li>Basic flow of information\n<ul>\n<li>Sensory input arrives and is represented in the upper layer.</li>\n<li>This input is associated with a location in the lower layer.</li>\n<li>When movement occurs, the lower layer changes to the expected new location.</li>\n<li>This causes a prediction of the next input in the upper layer.</li>\n</ul>\n</li>\n<li>If the location of a feature is ambiguous, then multiple locations are activated in the lower layer.</li>\n<li>Moving changes all possible locations and the information is used to eliminate any locations that don’t match.</li>\n<li>Simulations of this two-layer circuit lead to cortical columns that could learn hundreds of objects.</li>\n<li>Another requirement of cortical columns is the need to represent orientation.</li>\n<li>In the hippocampus, this information is represented by head direction cells and cortical columns may have cells with a similar function; we call them orientation cells.</li>\n<li>With about 150,000 cortical columns in the neocortex, not all columns are modeling objects.</li>\n<li>What are the rest of the columns doing?</li>\n</ul>\n<h2 id=\"chapter-6-concepts-language-and-high-level-thinking\" style=\"position:relative;\"><a href=\"#chapter-6-concepts-language-and-high-level-thinking\" aria-label=\"chapter 6 concepts language and high level thinking permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 6: Concepts, Language, and High-Level Thinking</h2>\n<ul>\n<li>Mountcastle proposed that every column in the neocortex performs the same basic function.</li>\n<li>This implies, however, that high-level cognitive abilities are fundamentally the same.</li>\n<li>E.g. Language, vision, touch, hearing.</li>\n<li>This proposal seems true given our evidence that the neocortex looks similar everywhere.</li>\n<li>What fundamental function can create all aspects of human intelligence?</li>\n<li>Another way to think of reference frames are as ways to organize knowledge.</li>\n<li>For complex topics such as DNA and space, we often imagine these items as if we could see and touch them.</li>\n<li>Thus, we organize facts about them using the same reference-frame mechanism that we use for everyday physical objects.</li>\n<li>The same applies to conceptual knowledge.</li>\n<li>E.g. Democracy, mathematics, relationships.</li>\n<li>We hypothesize that the brain arranges all knowledge using reference frames, and that thinking is a form of moving.</li>\n<li>Thinking occurs when we activate successive locations in reference frames.</li>\n<li>Premises for knowledge organized using reference frames\n<ul>\n<li>Reference frames are everywhere in the neocortex.</li>\n<li>Reference frames are used to model everything we know, not just physical objects.</li>\n<li>All knowledge is stored at locations relative to reference frames.</li>\n<li>Thinking is a form of movement.</li>\n</ul>\n</li>\n<li>If everything we know is stored in reference frames, then recalling a memory involves activating the appropriate locations in the appropriate reference frames.</li>\n<li>So thinking is invoking location after location in a reference frame.</li>\n<li>Review of the “what” and “where” visual pathways for object recognition and action respectively.</li>\n<li>Columns in the ‘what’ and ‘where’ pathways look similar, so why do they perform different functions?</li>\n<li>We argue that cortical grid cells in ‘what’ columns attach reference frames to objects, while cortical grid cells in ‘where’ columns attach reference frames to your body.</li>\n<li>E.g. ‘Where’ visual columns know where the hand and object are relative to the body so they can coordinate hand movements to the object. ‘What’ visual columns know the reference frame attached to the object and can identify it from its reference frame.</li>\n<li>In some ways, your body is just another object in the world and your brain can model it as such.</li>\n<li>Cortical columns can look similar but their function depends on what reference frames are anchored to them.</li>\n<li>How can cortical columns create models of abstract concepts?</li>\n<li>The trick is that reference frames don’t have to be anchored to anything physical.</li>\n<li>When a column learns a new model, part of the learning is also discovering what reference frame to use.</li>\n<li>Evidence for the four “knowledge as reference frame” premises\n<ul>\n<li>Method of loci\n<ul>\n<li>Also called the memory palace technique.</li>\n<li>Imagine placing the items you want to remember at different locations within a house/palace.</li>\n<li>To recall the items, you imagine walking through the house.</li>\n<li>This memory trick works because it assigns a location to a concept in a familiar reference frame.</li>\n<li>Note that the act of recalling is achieved by mentally moving through the house.</li>\n<li>The fact that the method of loci exists and works supports the premise that information is stored in reference frames and that the retrieval of information is a form of movement.</li>\n</ul>\n</li>\n<li>fMRI studies in humans\n<ul>\n<li>Review of fMRI but it isn’t too useful for the kind of research the author does.</li>\n<li>One fMRI study found that having participants move around in a virtual world was associated with grid cell activity in the entorhinal cortex, and the same activity was found in the frontal areas of the neocortex.</li>\n<li>This suggests that grid cells might exist in some parts of the neocortex.</li>\n<li>Learning conceptual knowledge can be difficult because multiple reference frames work.</li>\n<li>E.g. If you learn ten historical events, you could organize them by time, by location, or by important persons.</li>\n<li>Reference frames suggest different ways of thinking about the same events.</li>\n<li>Becoming an expert in a field requires discovering a good framework to represent the data and facts.</li>\n</ul>\n</li>\n<li>Mathematics\n<ul>\n<li>Suppose we want to prove a conjecture, this requires various intermediate results called equations.</li>\n<li>Also suppose that these equations are represented in your neocortex in a reference frame.</li>\n<li>Mathematical operations are movements that take you to different places in this reference frame.</li>\n<li>If we can find a set of operations—a set of movements through the reference frame—that get us to the conjecture, then we have proved the conjecture.</li>\n<li>Learning math requires learning not only the operations, but also useful reference frames.</li>\n<li>The common idea between mathematicians manipulating equations, explorers traveling through a forest, and fingers touching coffee cups, is that they all need map-like reference frames to know where they are and how to move to get where they want to be.</li>\n</ul>\n</li>\n<li>Politics\n<ul>\n<li>In politics, part of the reference frame is imagining what would happen if the law was enacted.</li>\n</ul>\n</li>\n<li>Language\n<ul>\n<li>Language is arguably our most important cognitive ability because we use it to share knowledge and experiences.</li>\n<li>There doesn’t seem to be any detailed theories of how the brain creates and understands language at the neuron level.</li>\n<li>Review of Wernicke’s and Broca’s areas.</li>\n<li>The unique asymmetry of language representation in the brain (mainly on the left hemisphere) suggests that something is different about Broca’s and Wernicke’s areas.</li>\n<li>But the anatomy of these two areas is similar to other areas of the neocortex, so maybe they only differ in subtle ways.</li>\n<li>It’s been argued that nesting and recursion are key attributes of language.</li>\n<li>We realized that each cortical column has the ability to learn nested and recursive structures.</li>\n<li>By creating a new reference frame that links reference frames together, we can recursively combine items.</li>\n<li>Cortical columns create reference frames for every object and these frames are populated with links to other reference frames.</li>\n<li>The brain models the world using reference frames populated with reference frames.</li>\n</ul>\n</li>\n<li>Expertise\n<ul>\n<li>Expertise requires good reference frames to organize knowledge and observations.</li>\n<li>E.g. Albert Einstein started with the same facts as other researchers but found a better way to organize them, allowing him to see surprising analogies and predictions.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>The common cortical algorithm is based on reference frames.</li>\n<li>The frames provide the substrate for learning the structure of the world, where things are, and how they change. This also applies to abstract concepts.</li>\n<li>Ironically, the correct reference frame to understand how the brain works is reference frames.</li>\n</ul>\n<h2 id=\"chapter-7-the-thousand-brains-theory-of-intelligence\" style=\"position:relative;\"><a href=\"#chapter-7-the-thousand-brains-theory-of-intelligence\" aria-label=\"chapter 7 the thousand brains theory of intelligence permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 7: The Thousand Brains Theory of Intelligence</h2>\n<ul>\n<li>It doesn’t make sense to study how societies work before understanding how people work.</li>\n<li>Similarly, it doesn’t make sense to study how the brain works before understanding how a cortical column works.</li>\n<li>We now know a lot about what cortical columns do.</li>\n<li>E.g. Each column is a sensory-motor system that can learn models of hundreds of objects based on reference frames.</li>\n<li>By extending this understanding to the neocortex, it’s now clear what the neocortex does.</li>\n<li>We call this the “Thousand Brains Theory of Intelligence” but before we explain this theory, we cover what it’s replacing.</li>\n<li>Existing view of the neocortex\n<ul>\n<li>Think of the neocortex as a flowchart where information from the senses is processed and passed from one region to the next; a hierarchy of feature detectors.</li>\n<li>E.g. Retina to V1 to V2 and so on.</li>\n<li>We go from simple features to complex features to complete objects.</li>\n<li>The main problem with this theory is that vision is treated as a static process.</li>\n<li>E.g. It doesn’t account for saccades nor head movement.</li>\n<li>Vision is an active sensory-motor process, not a static process.</li>\n<li>V1 and V2 are some of the largest regions in the human neocortex, but why is such a large area needed to detect small features? In contrast, the areas that process objects are smaller.</li>\n<li>The activity of most neurons in V1 can’t be explained by the hierarchy of features theory.</li>\n<li>Binding problem: how inputs from different senses are combined into a unified conscious experience.</li>\n<li>Another issue with the hierarchy of features theory is that it doesn’t explain how we learn the 3D structure of objects, how objects are composed of other objects, and how objects change over time.</li>\n</ul>\n</li>\n<li>New view of the neocortex\n<ul>\n<li>We propose that cortical columns can learn and recognize complete objects.</li>\n<li>But there’s a limit to how many objects a column can learn and what it can learn.</li>\n<li>E.g. A column can only learn models from its input data, whether that be visual, tactile, auditory, etc. data.</li>\n<li>Columns in V1 and V2 might both learn models of objects, but their models differ by scale.</li>\n<li>Knowledge is distributed in the brain and nothing we know is stored in one place. But it also isn’t stored everywhere.</li>\n<li>E.g. Where is the knowledge of a coffee cup stored? Some of it is in visual cortical columns and some in tactile columns. Information about any item is distributed among thousands of complementary models.</li>\n<li>This makes the knowledge robust to large losses of cortical columns.</li>\n<li>Complex systems function optimally when knowledge is distributed among many, but not too many, elements. The brain does this too.</li>\n<li>The brain continues to function even if a stroke or trauma kills thousands of columns.</li>\n<li>But the thousands brain theory still doesn’t solve the binding problem.</li>\n<li>E.g. If we have thousands of models, then how are they integrated to create our unified perception? How are sensory inputs bound into a singular percept?</li>\n<li>We propose that voting solves the binding problem; your perception is the consensus the columns reach by voting.</li>\n<li>E.g. Your five fingertips touching an object are like five voters, each with their own opinion of what the object is. On their own they can’t determine what the object is, but together they can.</li>\n<li>This is similar to the “Blind men and an elephant” parable where four men each touch a different part of an elephant and come to different conclusions, but combining their unique conclusions leads to recognizing the elephant.</li>\n<li>Voting works across different sensory modalities and only requires voting on what the object is and not its details.</li>\n<li>The only detail that matters is that everyone has a list of possible objects.</li>\n<li>However, voting can be more efficient when the cortical columns share their relative position to each other.</li>\n<li>Voting may be implemented in the brain by long-distance cortical connections between columns and regions.</li>\n<li>E.g. A column broadcasts what it thinks it’s observing to other columns, which are also broadcasting their votes. Then all voting columns converge on the majority vote.</li>\n<li>If you looked at the neocortex after an object was recognized, you would expect to see a stable pattern of activity in one layer of cells spanning thousands of columns.</li>\n<li>What we perceive is based on the stable voting neurons.</li>\n<li>But this doesn’t mean that all brain activity is stable because changing inputs do still lead to changing activity, just that there is also stable activity that’s easy to miss.</li>\n<li>The brain wants to reach a consensus and ambiguous stimuli cause that consensus to constantly fluctuate.</li>\n<li>E.g. In the case of visual illusions such as the Necker cube, the brain can’t reach a consensus which causes the cube to fluctuate.</li>\n<li>We are constantly learning models of everything we sense.</li>\n<li>E.g. If you go to a restaurant with family and they move around the dishes, you can close your eyes at any point and point to where the dishes are.</li>\n</ul>\n</li>\n<li>Hierarchy in the thousand brains theory\n<ul>\n<li>Is the neocortex organized as a hierarchy or as thousands of voting models?</li>\n<li>The anatomy of the neocortex suggests both theories are true.</li>\n<li>We propose that complete objects, not features, are passed between hierarchical levels.</li>\n<li>The entire world is learned as a complex hierarchy of objects located relative to other objects.</li>\n<li>But it’s still unclear how the neocortex does this.</li>\n</ul>\n</li>\n<li>The Thousand Brains Theory is a superset of the hierarchical model and explains how neurons predict their next input.</li>\n<li>E.g. Each column has models of complete objects and knows what should be sensed at each location on an object. If a column knows the current location of its input and how the eyes are moving, then it can predict the new location and thus the new input it will sense there.</li>\n<li>The voting mechanism of the theory explains why we have a single and unified perception of the world.</li>\n<li>Lastly, the Thousand Brains Theory shows how the neocortex learns 3D models of objects using reference frames.</li>\n<li>However, we should not leave with the incorrect impression that we understand everything about the neocortex.</li>\n<li>We now turn our attention to how the Thousand Brains Theory will impact our future.</li>\n</ul>\n<h1 id=\"part-ii-machine-intelligence\" style=\"position:relative;\"><a href=\"#part-ii-machine-intelligence\" aria-label=\"part ii machine intelligence permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Part II: Machine Intelligence</h1>\n<ul>\n<li>Review of scientific paradigms by Thomas Kuhn.</li>\n<li>In this second part, we cover how the Thousand Brains Theory will impact the future of artificial intelligence.</li>\n<li>The principles of intelligence described earlier will be the basis for a revolution in AI.</li>\n<li>The author sees the shift towards brain-based AI as inevitable.</li>\n</ul>\n<h2 id=\"chapter-8-why-there-is-no-i-in-ai\" style=\"position:relative;\"><a href=\"#chapter-8-why-there-is-no-i-in-ai\" aria-label=\"chapter 8 why there is no i in ai permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 8: Why There Is No “I” in AI</h2>\n<ul>\n<li>Review of AI summers and winters or the boom and bust cycles of AI.</li>\n<li>We’re currently in an AI summer driven by artificial neural networks.</li>\n<li>Is our current AI truly intelligent? Most people don’t think so.</li>\n<li>E.g. Deep learning networks don’t continuously learn and are inflexible, performing well only on one task.</li>\n<li>The goal of AI research is to create machines that exhibit human-level intelligence, also called artificial general intelligence (AGI).</li>\n<li>E.g. Rapidly learning new tasks, switching between tasks, and solving new problems.</li>\n<li>The essential question we face today is: Are we currently on a path to create AGI?</li>\n<li>The author believes that deep learning doesn’t put us on the path to creating truly intelligent machines. Instead, we need a different approach.</li>\n<li>Two paths to AGI\n<ul>\n<li>Get computers to outperform humans on specific tasks.\n<ul>\n<li>E.g. Playing Go or detecting cancerous cells in medical images.</li>\n<li>The hope is that we first get computers to outperform humans on a few difficult tasks, then we extend that process to outperform humans on every task.</li>\n<li>So far, this approach has faced challenges in the second part; in extending the process to every other task.</li>\n</ul>\n</li>\n<li>Get computers to flexibly perform multiple tasks.\n<ul>\n<li>With this path, we don’t need AI to outperform humans.</li>\n<li>Instead, we need AI to do as many tasks as we can and apply what they’ve learned from one task to another.</li>\n<li>The hope is that if we can build flexible AI systems, then we can eventually make systems that equal and surpass humans.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>The second path was favored in some of the early waves of AI but it proved too difficult.</li>\n<li>E.g. The amount of knowledge that a five-year-old child knows is enormous and AI researchers couldn’t figure out how to program this into a computer or how to get a computer to learn these facts.</li>\n<li>The difficultly with storing knowledge is representing it in a useful way.</li>\n<li>E.g. Learning everyday knowledge such as how balls bounce is effortless but difficult to program.</li>\n<li>This problem is called knowledge representation.</li>\n<li>The author doesn’t believe any kind of deep learning network will reach AGI if the network doesn’t model the world the way a brain does.</li>\n<li>Deep learning networks avoid the knowledge representation problem by relying on statistics and lots of data.</li>\n<li>Figuring out how the brain works is a hard, but necessary, first step to creating intelligent machines.</li>\n<li>The Thousand Brains Theory solves the problem of knowledge representation by using map-like reference frames.</li>\n<li>The naïve approach to knowledge representation is to list out all features and behaviors as rules.</li>\n<li>However, this leads to an infinite number of definitions and rules.</li>\n<li>The brain’s approach to knowledge representation is to learn a model, which embodies the knowledge.</li>\n<li>The cells in the neocortex learn a virtual model of the object and can use it to simulate actions on it.</li>\n<li>The knowledge is in the model.</li>\n<li>A general-purpose machine can learn to perform many tasks without erasing its memory and starting over.</li>\n<li>How can we tell if a machine is intelligent?</li>\n<li>The more complex the behavior, the more likely that it’s an intelligent agent in control. But the only certain way to tell is by looking inside.</li>\n<li>Four attributes of intelligence\n<ol>\n<li>Learn continuously\n<ul>\n<li>We are always learning and it isn’t a separate process from sensing and acting.</li>\n<li>We are constantly learning because the world is constantly changing.</li>\n<li>Flexibility requires continuous adjustment to changing conditions and new information.</li>\n</ul>\n</li>\n<li>Learn via movement\n<ul>\n<li>Since our senses are limited by their orientation and range, movement can increase a sense’s functional range.</li>\n<li>Movement is generated by cortical columns that predict what its next input will be given the movement.</li>\n</ul>\n</li>\n<li>Many models\n<ul>\n<li>Knowledge about any object or concept is distributed among many complementary models.</li>\n<li>This provides robustness to damage and loss.</li>\n<li>The key to making many models work together is voting; long-range connections in the neocortex allow columns to vote on the object they’re sensing.</li>\n</ul>\n</li>\n<li>Using reference frames to store knowledge\n<ul>\n<li>Reference frames store knowledge, make predictions, create plans, and perform movements.</li>\n<li>The mechanism underlying thinking is that it activates one location at a time in a reference frame, and retrieves the associated piece of knowledge.</li>\n<li>Each cortical column creates its own set of reference frames using cells similar to grid and place cells.</li>\n</ul>\n</li>\n</ol>\n</li>\n<li>Without reference frames, artificial networks can’t learn the 3D structure of objects or how they change.</li>\n<li>Intelligence shouldn’t be measured by how well the agent performs a single task, but rather intelligence should be measured by how well the agent learns and uses knowledge.</li>\n<li>E.g. We’re intelligent not because we can do one thing well, but because we can learn to do practically anything well.</li>\n</ul>\n<h2 id=\"chapter-9-when-machines-are-conscious\" style=\"position:relative;\"><a href=\"#chapter-9-when-machines-are-conscious\" aria-label=\"chapter 9 when machines are conscious permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 9: When Machines Are Conscious</h2>\n<ul>\n<li>Review of the hard and easy problems of consciousness.</li>\n<li>Thought experiment\n<ul>\n<li>Imagine that your brain was reset to the exact state it was in when you woke up this morning.</li>\n<li>But before the reset, you had gotten up and gone about your day, say washing your car.</li>\n<li>After the reset, all memories of what you did are erased and you wake up believing that you had just woken up.</li>\n<li>You would deny washing your car and deny being conscious that you did it, but you were conscious when you washed your car.</li>\n</ul>\n</li>\n<li>This thought experiment shows us that our sense of awareness, what many people would call being conscious, requires that we form moment-to-moment memories of our actions.</li>\n<li>Consciousness also requires that we form moment-to-moment memories of our thoughts.</li>\n<li>Thinking is just a sequential activation of neurons in the brain.</li>\n<li>If we didn’t remember our thoughts, we would be unaware of why we were doing anything.</li>\n<li>E.g. Sometimes we enter a room but forget what we wanted to do in that room.</li>\n<li>Active neurons in the brain sometimes represent our present experience and sometimes represent a previous experiment or thought.</li>\n<li>It is this accessibility of the past, the ability to mentally time travel, that gives us our sense of presence and awareness.</li>\n<li>If we couldn’t replay our recent thoughts and experiences, then we would be unaware that we are alive.</li>\n<li>Our awareness depends on continuously forming memories of recent experiences and thoughts.</li>\n<li>Qualia\n<ul>\n<li>The nerve fibers that enter the brain from the eyes, ears, and skin look the same and use the same unit of information—spikes.</li>\n<li>If you look at the inputs to the brain, you can’t tell what they represent.</li>\n<li>And yet, vision feels different from hearing and neither feels like spikes.</li>\n<li>Qualia: how sensory inputs are perceived and felt.</li>\n<li>Given that all sensations are created by identical nerve fibers and identical spikes, why do they feel different?</li>\n<li>The answer is that the pathways are different. They come from different sources and lead to different destinations.</li>\n<li>Qualia are part of the brain’s model of the world and are subjective (unique to each person).</li>\n<li>Qualia are subjective because every person has a unique organization of pathways, leading to unique sensations for identical stimuli.</li>\n<li>E.g. The taste of a pickle for me might be different from how you perceive the taste of a pickle because we have different taste sensors sending information on different pathways to different destinations.</li>\n<li>If two people perceive the same input as different, this suggests that their models are different.</li>\n<li>E.g. Color is created by the brain; it’s a property of the brain’s model of surfaces and not a property of light.</li>\n</ul>\n</li>\n<li>If qualia are a property of the brain’s model of the world, then how does the brain create them?</li>\n<li>In the same way that the brain learns models of the world by movement, it also learns the associated qualia.</li>\n<li>E.g. To learn the different shades of green, you change the orientation of green objects or change your vantage point for green objects, thus exposing you to different shades of green. Then cortical columns can create a reference frame for inputs at different surface orientations.</li>\n<li>However, we don’t know if the qualia of color are actually modeled this way.</li>\n<li>Not all qualia are learned.</li>\n<li>E.g. The feeling of pain is almost certainly innate.</li>\n<li>So, pain can’t be understood in the same way as the color green.</li>\n</ul>\n<h2 id=\"chapter-10-the-future-of-machine-intelligence\" style=\"position:relative;\"><a href=\"#chapter-10-the-future-of-machine-intelligence\" aria-label=\"chapter 10 the future of machine intelligence permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 10: The Future of Machine Intelligence</h2>\n<ul>\n<li>Nothing we call AI today is intelligent because it doesn’t exhibit the flexibility described in the earlier chapters.</li>\n<li>There are no technical reasons preventing us from creating intelligent machines.</li>\n<li>But as history shows, we are ignorant today about what intelligent machines will look like in seventy years from now, similar to how the 1950s were ignorant of innovations in media, communications, and computers.</li>\n<li>Although we can’t predict the future, the Thousand Brains Theory can help us define the boundaries of AI.</li>\n<li>One important boundary is that intelligent machines will not be like humans because of our brain’s division into old versus new brain.</li>\n<li>E.g. We don’t need to replicate the basic functions of life in machines such as breathing, survival, procreation, and our innate behaviors.</li>\n<li>We can choose which parts of the brain we want and which parts we don’t.</li>\n<li>Intelligence is the ability of a system to learn a model of the world, but the model itself is valueless, emotionless, and has no goals.</li>\n<li>Goals and values are provided by the system using the model.</li>\n<li>E.g. A map can be used for war, trade, or exploration.</li>\n<li>Designing an intelligent machine based on the brain can be broken down into three parts: embodiment, old brain, and new brain (neocortex).</li>\n<li>Embodiment\n<ul>\n<li>We learn by moving; moving our sensors to things in the world.</li>\n<li>Intelligent machines also need sensors and the ability to move them.</li>\n<li>Reference frames are used to know where the sensors are.</li>\n<li>We have an enormous range and quantity of sensors, and machines that approach or exceed human intelligence will have as many, if not more, sensors than us.</li>\n<li>The important point is that intelligent machines need moveable sensory inputs to learn a model of the world.</li>\n<li>There’s no reason to limit the sensors to the types we know and to specific locations.</li>\n<li>E.g. An intelligent machine with sensors distributed over Earth’s surface might understand the behavior of global weather in the same way we understand the behavior of our skin.</li>\n<li>AI will likely take many different forms, many forms unfamiliar with our ideas based on biological intelligence.</li>\n</ul>\n</li>\n<li>Old brain\n<ul>\n<li>There are some parts of the old brain that are required to build intelligent machines.</li>\n<li>E.g. Basic movements and behaviors tied to embodiment.</li>\n<li>We don’t want the neocortex to handle lower-level movement such as walking, balancing, and maintaining homeostasis.</li>\n<li>Instead, the neocortex should control the higher-level aspects of behavior such as planning, optimization, and flexibility.</li>\n<li>An intelligent machine must have goals and motivations because the neocortex, on its own, doesn’t create goals, motivations, or emotions.</li>\n<li>The neocortex does not lead.</li>\n<li>An intelligent machine will need some form of goals and motivations, but goals and motivations aren’t a consequence of intelligence and won’t appear on their own.</li>\n</ul>\n</li>\n<li>New brain\n<ul>\n<li>The third component for an intelligent machine is a general-purpose learning system that performs the same functions as the neocortex.</li>\n<li>We cover two design parameters: speed and capacity.</li>\n<li>Neurons take at least five milliseconds to do anything useful. This is very slow compared to transistors made of silicon.</li>\n<li>But just because an intelligent machine can operate faster than a biological brain doesn’t mean that the entire machine runs faster or learns faster.</li>\n<li>E.g. An intelligent and robotic construction worker might think faster, but the bottleneck isn’t intelligence, it’s the time required to carry out the work.</li>\n<li>What if we created an artificial brain with a thousand times more cortical columns than in human brains?</li>\n<li>We know that in humans, the size of neocortical regions varies considerably and this size leads to increases in processing power for that sense.</li>\n<li>E.g. Increased visual region area leads to increased visual acuity.</li>\n<li>Instead of increasing the size of regions, we could also create more regions and connect them in complex ways.</li>\n<li>This is similar to the difference between monkeys and humans.</li>\n<li>E.g. Both monkeys and humans have similar visual abilities, but humans have a bigger overall neocortex with more regions.</li>\n<li>Another way to think about capacity is in terms of brain wiring.</li>\n<li>When we’re born, our brain has an abundance of wiring making it easier to learn new types of knowledge early in life.</li>\n<li>The removal of unused wiring during childhood based on early life experiences is both a blessing and curse though.</li>\n<li>The curse is that it makes it difficult to learn new types of knowledge later in life.</li>\n<li>Intelligent machines don’t have the same constraints related to neural wiring.</li>\n<li>This flexibility in connectivity could be one of the greatest advantages of machine intelligence over biological intelligence as it allows machines to keep all their options open.</li>\n</ul>\n</li>\n<li>Another difference between us and machine intelligence is that machines can be cloned.</li>\n<li>This leads to learning only once and then cloning the abilities to other machines.</li>\n<li>Not everyone is as optimistic about the benefits of machine intelligence though.</li>\n</ul>\n<h2 id=\"chapter-11-the-existential-risks-of-machine-intelligence\" style=\"position:relative;\"><a href=\"#chapter-11-the-existential-risks-of-machine-intelligence\" aria-label=\"chapter 11 the existential risks of machine intelligence permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 11: The Existential Risks of Machine Intelligence</h2>\n<ul>\n<li>Many high-profile technologists, scientists, and philosophers have warned us that the creation of intelligent machines might lead to human extinction or subjugation.</li>\n<li>AI can be used by bad people to do bad things, or the AI itself might be a bad actor and decide to wipe out humanity on its own.</li>\n<li>The first existential risk of machine intelligence is an intelligence explosion.</li>\n<li>E.g. We create machines smarter than us and those machines are better than us at everything, including creating smarter machines. So smart machine creates smarter machine, which then creates another smarter machine and so on.</li>\n<li>So, the intelligence of the machine explodes and vastly surpasses us.</li>\n<li>The second existential risk is goal misalignment.</li>\n<li>E.g. Intelligent machines pursue goals that go against our goals and we can’t stop them.</li>\n<li>A common theme among these scenarios is that we lose control of our creations.</li>\n<li>The author, however, doesn’t completely agree with these arguments because what we know about biological intelligence suggests different limitations.</li>\n<li>Intelligence requires a model of the world because the model is used to recognize objects, manipulate them, and to predict the consequences of our actions.</li>\n<li>And learning these models takes time; there’s no substitute for experience.</li>\n<li>The speed of learning is limited by the need to physically interact with the world.</li>\n<li>No notes on the goal-misalignment threat.</li>\n<li>The author is confident that intelligent machines don’t pose an existential threat to humanity.</li>\n<li>We should distinguish between three things\n<ul>\n<li>Replication: anything capable of self-replication is dangerous. Intelligent machines won’t have the ability or desire to self-replicate unless we desire it.</li>\n<li>Motivations: biological motivations and drives are a consequence of evolution and the desire to replicate. Without such pressures and drives, machines don’t develop the desire to replicate.</li>\n<li>Intelligence: an intelligent machine won’t start self-replicating on its own, nor will it spontaneously develop drives and motivations.</li>\n</ul>\n</li>\n<li>This isn’t to say that machine intelligence isn’t dangerous—it can be in the wrong hands—but that machine intelligence isn’t inherently dangerous nor will it become dangerous unless we specify so.</li>\n</ul>\n<h1 id=\"part-iii-human-intelligence\" style=\"position:relative;\"><a href=\"#part-iii-human-intelligence\" aria-label=\"part iii human intelligence permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Part III: Human Intelligence</h1>\n<ul>\n<li>Review of the evolution of life starting from 3.5 billion years ago.</li>\n<li>Life was driven by competition, survival, and reproduction; nothing else mattered.</li>\n<li>Our intelligence is the source of our success, but it has also become an existential threat.</li>\n</ul>\n<h2 id=\"chapter-12-false-beliefs\" style=\"position:relative;\"><a href=\"#chapter-12-false-beliefs\" aria-label=\"chapter 12 false beliefs permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 12: False Beliefs</h2>\n<ul>\n<li>Review of the brain-in-a-vat thought experiment.</li>\n<li>Your brain is isolated in a dark box with no sensors itself. The only way your brain knows anything about reality is through the sensory nerve fibers that enter the skull.</li>\n<li>There is no light or sound entering the skull, only electrical spikes.</li>\n<li>There are also electrical signals coming out of your brain to your muscles, which move your body and its sensors. The movement changes what part of the world the brain senses.</li>\n<li>By repeatedly sensing and moving, sensing and moving, your brain learns a model of the world outside the skull.</li>\n<li>Remember that no light, touch, or sound enters the brain, only spikes, and since we don’t perceive spikes, then everything we do perceive must be fabricated in the brain.</li>\n<li>Don’t the input spikes represent light and sound though?</li>\n<li>Sort of, the spikes represent a slice of the possible light and sound, a slice captured by your sensory organs.</li>\n<li>With a different set of sensors, the same universe would lead to different perceptual experiences.</li>\n<li>E.g. Seeing ultraviolet light or hearing sonar waves.</li>\n<li>The brain only knows about a subset of the real world and what we perceive is our model of the world, not the world itself.</li>\n<li>At any moment, only a subset of all neurons are active and these active neurons represent what we’re currently thinking and perceiving.</li>\n<li>Importantly, these thoughts and perceptions are relative to the brain’s model of the world and not the real world outside the skull.</li>\n<li>So, the world we perceive is a simulation of the real world even though it doesn’t feel like it.</li>\n<li>As we move, the sensory inputs to the brain invoke the appropriate parts of our world model, which is what we perceive and believe to be the real world.</li>\n<li>Our reality is similar to the brain-in-a-vat experiment except instead of a simulated computer reality, it’s a simulated model of reality.</li>\n<li>A nerve fiber representing pressure on a fingertip doesn’t convey any information about where the fingertip is.</li>\n<li>E.g. The finger could be in front of you or behind you, and yet you perceive the sense of touch as being at some location relative to your body.</li>\n<li>You perceive your finger to be located somewhere because the cells that represent the location of your finger say so. But these cells can be wrong about the location.</li>\n<li>E.g. The case of “phantom limb” where people who lose a limb often perceive the missing limb as still there. The sensations are felt as if they are “out there”, located at particular locations on the missing limb.</li>\n<li>E.g. The case of “alien limb” where people have a normal limb that doesn’t feel like it belongs to them. People with an alien limb may try to amputate their own limb to remove the foreign-feeling limb.</li>\n<li>E.g. The rubber hand illusion.</li>\n<li>Taken together, these three cases show how we can perceive things that don’t exist (phantom limb) and we can incorrectly perceive things that do exist (alien limb and rubber hand).</li>\n<li>The brain’s model is clearly wrong for these cases to exist.</li>\n<li>False belief: when the brain’s model believes that something exists when it doesn’t.</li>\n<li>In the case of phantom limbs, even though the limb is gone, the cortical columns that model the limb are still present and still model the limb.</li>\n<li>So, the patient perceives sensations from the limb even though it doesn’t exist.</li>\n<li>No notes on the flat-Earth false belief.</li>\n<li>Model repair after a prediction error is built into the neocortex and normally works.</li>\n<li>No notes on false and viral world models, and memes.</li>\n<li>Life isn’t about having a correct model of the world, but about replication and survival.</li>\n<li>Language allows us to extend our model of the world to include stimuli that we haven’t personally experienced.</li>\n</ul>\n<h2 id=\"chapter-13-the-existential-risks-of-human-intelligence\" style=\"position:relative;\"><a href=\"#chapter-13-the-existential-risks-of-human-intelligence\" aria-label=\"chapter 13 the existential risks of human intelligence permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 13: The Existential Risks of Human Intelligence</h2>\n<ul>\n<li>This chapter focuses on two fundamental systemic risks associated with the human brain.</li>\n<li>The first risk is associated with the older parts of our brain, the second risk is associated with the neocortex and intelligence.</li>\n<li>No notes on the first risk because I don’t believe in the “older parts” of the brain.</li>\n<li>All innate behaviors, whether we find them desirable or not, exist because they were successful adaptations.</li>\n<li>No notes on population growth and climate change.</li>\n</ul>\n<h2 id=\"chapter-14-merging-brains-and-machines\" style=\"position:relative;\"><a href=\"#chapter-14-merging-brains-and-machines\" aria-label=\"chapter 14 merging brains and machines permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 14: Merging Brains and Machines</h2>\n<ul>\n<li>Two ways we could merge with machines\n<ul>\n<li>Upload our brains into computers</li>\n<li>Merging our brains with computers</li>\n</ul>\n</li>\n<li>No notes on genes and how we exist primarily to replicate genes.</li>\n<li>Uploading your brain\n<ul>\n<li>This is one way to live forever as a computer-simulated version of our self.</li>\n<li>If we want to upload you and have you be normal, then we have to upload the entire brain and not just parts of it.</li>\n<li>We should upload everything because the brain is interconnected in complex ways such that missing parts would result in serious problems similar to a brain lesion.</li>\n<li>However, this also extends to your body as we would need to simulate your sensory organs, your muscles, the fluids in your body, etc.</li>\n<li>We can’t ignore parts of the brain or body without messing something up.</li>\n<li>How would we read the details of your brain to upload it?</li>\n<li>Neurons and synapses have complex shapes and internal structures that aren’t easily captured and stored.</li>\n<li>Our current technology doesn’t have enough power nor capacity to store every detail for a dead brain, let alone a living one.</li>\n<li>Getting and storing the details needed to recreate you in a computer is so difficult that we might never be able to do it.</li>\n<li>Uploading your brain is really splitting yourself into two people.</li>\n<li>Making a silicon copy of ourselves won’t achieve immortality any more than having children will.</li>\n</ul>\n</li>\n<li>Merging your brain with a computer\n<ul>\n<li>In this case, electrodes are placed into your brain that connect you with a computer.</li>\n<li>So your brain can now directly receive and send information with computers.</li>\n<li>This would enhance our mental abilities as we could rely on computers for storage and processing.</li>\n<li>One reason to merge with machines is to counter the treat of superintelligent AIs by merging with them.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"chapter-15-estate-planning-for-humanity\" style=\"position:relative;\"><a href=\"#chapter-15-estate-planning-for-humanity\" aria-label=\"chapter 15 estate planning for humanity permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 15: Estate Planning for Humanity</h2>\n<ul>\n<li>Knowledge is what we’ve learned about the world.</li>\n<li>This chapter covers the idea that knowledge is worth preserving and propagating, even if that means doing so independently of humans.</li>\n<li>If we went extinct, then everything we’ve accomplished would be lost forever, which is the same as having never existed.</li>\n<li>No notes on the existential risks to humanity.</li>\n<li>E.g. The Sun exploding in billions of years, climate change, nuclear weapons, asteroid strike.</li>\n<li>Three ways to communicate with the future\n<ul>\n<li>Message in a bottle\n<ul>\n<li>The bottle and your message are a means to not be forgotten.</li>\n<li>E.g. The gold records on the Pioneer and Voyager probes.</li>\n</ul>\n</li>\n<li>Leave the lights on\n<ul>\n<li>Review of the SETI and METI programs.</li>\n<li>If we expect to discover intelligent life in our galaxy, it requires that intelligent life occurs often and lasts a long time, enough time to intersect the existence of other intelligent life.</li>\n</ul>\n</li>\n<li>Wiki Earth\n<ul>\n<li>No notes on this section.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"chapter-16-genes-versus-knowledge\" style=\"position:relative;\"><a href=\"#chapter-16-genes-versus-knowledge\" aria-label=\"chapter 16 genes versus knowledge permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 16: Genes Versus Knowledge</h2>\n<ul>\n<li>No notes for this chapter because it isn’t relevant to the brain.</li>\n</ul>\n<h2 id=\"chapter-17-final-thoughts\" style=\"position:relative;\"><a href=\"#chapter-17-final-thoughts\" aria-label=\"chapter 17 final thoughts permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chapter 17: Final Thoughts</h2>\n<ul>\n<li>Reverse engineering the brain and understanding intelligence is, in the author’s opinion, the most important scientific quest humans will ever undertake.</li>\n<li>Review of the Thousand Brains Theory of Intelligence, the author’s arguments that present AIs aren’t intelligent (intelligence requires learning a model of the world), and the author’s opinions of the human condition viewed through the lens of intelligence and brain theory.</li>\n<li>As far as we know, the human brain is the only thing in the universe that knows the universe exists.</li>\n</ul>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#part-i-a-new-understanding-of-the-brain\">Part I: A New Understanding of the Brain</a></p>\n<ul>\n<li><a href=\"#chapter-1-old-brainnew-brain\">Chapter 1: Old Brain—New Brain</a></li>\n<li><a href=\"#chapter-2-vernon-mountcastles-big-idea\">Chapter 2: Vernon Mountcastle’s Big Idea</a></li>\n<li><a href=\"#chapter-3-a-model-of-the-world-in-your-head\">Chapter 3: A Model of the World in Your Head</a></li>\n<li><a href=\"#chapter-4-the-brain-reveals-its-secrets\">Chapter 4: The Brain Reveals Its Secrets</a></li>\n<li><a href=\"#chapter-5-mapsin-the-brain\">Chapter 5: Mapsin the Brain</a></li>\n<li><a href=\"#chapter-6-concepts-language-and-high-level-thinking\">Chapter 6: Concepts, Language, and High-Level Thinking</a></li>\n<li><a href=\"#chapter-7-the-thousand-brains-theory-of-intelligence\">Chapter 7: The Thousand Brains Theory of Intelligence</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#part-ii-machine-intelligence\">Part II: Machine Intelligence</a></p>\n<ul>\n<li><a href=\"#chapter-8-why-there-is-no-i-in-ai\">Chapter 8: Why There Is No “I” in AI</a></li>\n<li><a href=\"#chapter-9-when-machines-are-conscious\">Chapter 9: When Machines Are Conscious</a></li>\n<li><a href=\"#chapter-10-the-future-of-machine-intelligence\">Chapter 10: The Future of Machine Intelligence</a></li>\n<li><a href=\"#chapter-11-the-existential-risks-of-machine-intelligence\">Chapter 11: The Existential Risks of Machine Intelligence</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#part-iii-human-intelligence\">Part III: Human Intelligence</a></p>\n<ul>\n<li><a href=\"#chapter-12-false-beliefs\">Chapter 12: False Beliefs</a></li>\n<li><a href=\"#chapter-13-the-existential-risks-of-human-intelligence\">Chapter 13: The Existential Risks of Human Intelligence</a></li>\n<li><a href=\"#chapter-14-merging-brains-and-machines\">Chapter 14: Merging Brains and Machines</a></li>\n<li><a href=\"#chapter-15-estate-planning-for-humanity\">Chapter 15: Estate Planning for Humanity</a></li>\n<li><a href=\"#chapter-16-genes-versus-knowledge\">Chapter 16: Genes Versus Knowledge</a></li>\n<li><a href=\"#chapter-17-final-thoughts\">Chapter 17: Final Thoughts</a></li>\n</ul>\n</li>\n</ul>","timeToRead":36,"frontmatter":{"title":"A Thousand Brains","date":"August 22, 2022","book_authors":"Jeff Hawkins","categories":["Books"]}}},"pageContext":{"slug":"/books/a-thousand-brains/","previous":{"fields":{"slug":"/textbooks/vision/"},"frontmatter":{"title":"Vision","layout":"post"}},"next":{"fields":{"slug":"/papers/msc-neuroscience-notes/"},"frontmatter":{"title":"MSc Neuroscience Paper Notes","layout":"post"}}}},"staticQueryHashes":["1031357278","1878747374","3666494887"],"slicesMap":{}}